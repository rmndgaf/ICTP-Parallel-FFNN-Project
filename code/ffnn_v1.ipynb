{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YXgX0NF8OMjJ",
        "outputId": "51e79e61-2997-4e57-ead6-27afb4a9e2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3vbncErZOMjK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Implementation of a Node\n",
        "# A node should be able to take an input vector (which is either the input or the previous layer)\n",
        "# Sum the values from the previous node\n",
        "# Pass the sum to an activation value\n",
        "# Return the value as its own value\n",
        "\n",
        "class node(object):\n",
        "  def __init__(self, inputVec = [], weight = [], activation = None):\n",
        "    # Number of Inputs\n",
        "    self.inputVector = inputVec\n",
        "    self.nodeWeights = weight\n",
        "    self.actSelect = activation\n",
        "    self.bias = np.random.rand()\n",
        "\n",
        "    # Summation of Connected Notes\n",
        "    self.nodeSum = self.summationNodes()\n",
        "\n",
        "    # Activation function\n",
        "    self.nodeVal = self.activation()\n",
        "\n",
        "  # Parallelizable for all input values\n",
        "  def summationNodes(self):\n",
        "    sumOfVec = 0\n",
        "    for (i, j) in zip(self.inputVector, self.nodeWeights):\n",
        "        sumOfVec = sumOfVec + i * j\n",
        "    return (sumOfVec + self.bias)\n",
        "\n",
        "  def activation(self):\n",
        "    if (self.actSelect == \"sigmoid\"):\n",
        "      return (1 / (1 + pow(math.e, -self.nodeSum)))\n",
        "\n",
        "    if (self.actSelect == \"relu\"):\n",
        "      return (max(0.1*self.nodeSum, self.nodeSum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ix53YnD_OMjL"
      },
      "outputs": [],
      "source": [
        "# For the mutli-layer perceptron\n",
        "# We should first be able to store the input vector in an array\n",
        "# Create N (user-defined number) nodes\n",
        "# Allow users to add layers with custom nodes as a method of the class\n",
        "# The output node automatically implements\n",
        "\n",
        "class mlp(node):\n",
        "\n",
        "  def __init__ (self):\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = None\n",
        "    self.outputClass = []\n",
        "    self.inputVector = [] # This is the vector we pass to the first hidden layer\n",
        "    self.outputVal = None\n",
        "    self.outputIndex = None\n",
        "\n",
        "  def activate(self, inputVector, numClass):\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = len(inputVector)\n",
        "    self.outputClass = numClass\n",
        "    self.inputVector = inputVector # This is the vector we pass to the first hidden layer\n",
        "\n",
        "    # Simulate hidden later\n",
        "    layer1 = self.addLayer(numNodes = 10, prevLayer = self.inputVector)\n",
        "    layer2 = self.addLayer(numNodes = 10, prevLayer = layer1)\n",
        "    layer3 = self.addLayer(numNodes = 10, prevLayer = layer2)\n",
        "    layer4 = self.addLayer(numNodes = 5, prevLayer = layer3)\n",
        "    self.outputVal, self.outputIndex = self.outputLayer(layer4)\n",
        "\n",
        "  # This intendeds to simulate the hidden layers\n",
        "  def addLayer(self, numNodes = None, prevLayer = None):\n",
        "    #weights = [np.random.rand() for i in range(len(inputVector))]\n",
        "\n",
        "    if numNodes == None:\n",
        "      numNodes = self.inputSize\n",
        "\n",
        "    nextLayer = []\n",
        "    for i in range(numNodes):\n",
        "      # Create the nodes\n",
        "      nextLayer.append(node(self.inputVector, [np.random.rand() for j in range(len(self.inputVector))], activation='relu'))\n",
        "\n",
        "    outputValues = []\n",
        "    for i in nextLayer:\n",
        "      i.summationNodes()\n",
        "      i.activation()\n",
        "      outputValues.append(i.nodeVal)\n",
        "\n",
        "    return outputValues\n",
        "\n",
        "  def outputLayer(self, lastHidden):\n",
        "    outLayer = []\n",
        "    for i in range(self.outputClass):\n",
        "      outLayer.append(node(lastHidden, [np.random.rand() for j in range(len(self.inputVector))], activation='sigmoid'))\n",
        "\n",
        "    endVals = []\n",
        "    for i in range(self.outputClass):\n",
        "      endVals.append(outLayer[i].nodeVal)\n",
        "      #print(\"Class \", i, \" : \", outLayer[i].nodeVal)\n",
        "\n",
        "    return max(endVals), endVals.index(max(endVals))\n",
        "\n",
        "  def printResult(self):\n",
        "    print(\"Predicted Class: \", self. outputIndex)\n",
        "\n",
        "  def getPrediction(self):\n",
        "    return self.outputIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMwSVNr6OMjL"
      },
      "source": [
        "# Sample with the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vDeWLDQ6OMjM",
        "outputId": "e41424df-ce08-479e-ecdf-898f96599c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ],
      "source": [
        "# Loading the IRIS Dataset for Classification\n",
        "!pip install ucimlrepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "df_X = iris.data.features\n",
        "df_y = iris.data.targets\n",
        "\n",
        "df_X = pd.DataFrame(df_X)\n",
        "#df_X.head()\n",
        "\n",
        "df_y = pd.DataFrame(df_y)\n",
        "#df_y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3QyUbwVTOMjM",
        "outputId": "28d114b1-c5e0-4b57-cd96-fd4767c8d200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal length  150 non-null    float64\n",
            " 1   sepal width   150 non-null    float64\n",
            " 2   petal length  150 non-null    float64\n",
            " 3   petal width   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   150 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.3+ KB\n",
            "     class\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "..     ...\n",
            "145      2\n",
            "146      2\n",
            "147      2\n",
            "148      2\n",
            "149      2\n",
            "\n",
            "[150 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "0        50\n",
              "1        50\n",
              "2        50\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Perform some data wrangling/preparation\n",
        "\n",
        "# Check info on the attributes\n",
        "df_X.info() # All values are same type, check if any missing values\n",
        "df_X.isnull().sum() # To check if there are any null values\n",
        "\n",
        "# Checking the output\n",
        "df_y.info()\n",
        "\n",
        "# Object Types must be converted\n",
        "df_y_original = df_y.copy() # Store the df somewhere before modifying\n",
        "\n",
        "df_y.value_counts()\n",
        "\n",
        "# Reveals Three Classes\n",
        "# Map classes to corresponding numerical values\n",
        "\n",
        "outMap = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
        "df_y.replace(outMap, inplace=True)\n",
        "\n",
        "print(df_y)\n",
        "df_y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpNbdxWTOMjM"
      },
      "source": [
        "# Test out the CPU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DEO3XYLlOMjN"
      },
      "outputs": [],
      "source": [
        "def testModel(model, inVector, appendList = []):\n",
        "  for i in inVector:\n",
        "    model.activate(i, 3)\n",
        "    appendList.append(model.getPrediction())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UU2euBKHOMjN"
      },
      "outputs": [],
      "source": [
        "predictedVals = []\n",
        "model = mlp()\n",
        "\n",
        "testModel(model, np.array(df_X), predictedVals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EzmrjTQ4OMjN",
        "outputId": "8fc65a41-3123-4bb2-b07d-9152f9fe6090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Predictions / Total Predictions: 51 / 150 .\n",
            "Custom Feedforward Neural Network is: 34 % Accurate\n"
          ]
        }
      ],
      "source": [
        "trueOutput = np.array(df_y)\n",
        "\n",
        "correctPreds, totalPreds = 0, len(trueOutput)\n",
        "for i in range(totalPreds):\n",
        "  if predictedVals[i] == trueOutput[i]:\n",
        "    correctPreds = correctPreds + 1\n",
        "\n",
        "print(\"Correct Predictions / Total Predictions: {} / {} .\".format(correctPreds, totalPreds))\n",
        "print(\"Custom Feedforward Neural Network is: {} % Accurate\".format(round(correctPreds/totalPreds * 100), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzonciwQOMjN"
      },
      "source": [
        "# Implementation using CuPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z1LansRWOMjN"
      },
      "outputs": [],
      "source": [
        "# For implementation with CuPY\n",
        "import cupy as cp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fD-k6mclOMjO"
      },
      "outputs": [],
      "source": [
        "# Reduction Kernel per Node\n",
        "nodeSum_kernel = cp.ReductionKernel(\n",
        "    'T inputVec, U inputWeight',  # input params\n",
        "    'T outputVec',  # output params\n",
        "    'inputVec * inputWeight',  # map\n",
        "    'a + b',  # reduce\n",
        "    'outputVec = a',  # post-reduction map\n",
        "    '0',  # identity value\n",
        "    'nodeSum_kernel'  # kernel name\n",
        ")\n",
        "\n",
        "class MLPcupy():\n",
        "\n",
        "  def __init__ (self):\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = None\n",
        "    self.outputClass = []\n",
        "    self.inputVector = [] # This is the vector we pass to the first hidden layer\n",
        "    self.outputVal = None\n",
        "    self.outputIndex = None\n",
        "\n",
        "  def activate(self, inputVector, numClass):\n",
        "  # For now, this is just forward propagation\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = len(inputVector)\n",
        "    self.outputClass = numClass\n",
        "    self.inputVector = inputVector # This is the vector we pass to the first hidden layer\n",
        "\n",
        "    # Simulate hidden later\n",
        "    layer1 = self.addLayer(numNodes = 10, prevLayer = self.inputVector, activation = \"relu\")\n",
        "    #print(layer1)\n",
        "    layer2 = self.addLayer(numNodes = 10, prevLayer = layer1, activation = \"relu\")\n",
        "    #print(layer2)\n",
        "    layer3 = self.addLayer(numNodes = 10, prevLayer = layer2, activation = \"relu\")\n",
        "    #print(layer3)\n",
        "    layer4 = self.addLayer(numNodes = 5, prevLayer = layer3, activation = \"relu\")\n",
        "    #print(layer4)\n",
        "\n",
        "    # Simulate output layer\n",
        "    self.outputIndex = self.outputLayer(layer4)\n",
        "\n",
        "  # This intendeds to simulate the hidden layers\n",
        "  def addLayer(self, numNodes = None, prevLayer = None, activation = \"\"):\n",
        "\n",
        "    if numNodes == None:\n",
        "      print(\"Indicate number of Nodes.\")\n",
        "      return\n",
        "\n",
        "    # This will be where we store the new values\n",
        "    newLayer = cp.zeros(numNodes)\n",
        "    nodeValue = cp.zeros(len(prevLayer))\n",
        "\n",
        "    for i in range(numNodes):\n",
        "    # add_kernel(grid_size, block_size, (x1, x2, y, size))\n",
        "    # nodeSum_kernel(const float* inputVector, const float* layerWeights, float* outputNode, const float* bias)\n",
        "      #print(\"Nodes: \", prevLayer)\n",
        "      weights = cp.array([cp.random.random() for i in range(len(prevLayer))])\n",
        "      #print(\"Weights: \", weights)\n",
        "      bias = cp.random.random()\n",
        "      #print(\"Bias: \", bias)\n",
        "\n",
        "      newLayer[i] = nodeSum_kernel(cp.array(prevLayer), cp.array(weights), cp.random.random()) + bias\n",
        "      #print(\"Node \", i, \" : \", newLayer[i])\n",
        "\n",
        "      if (activation == \"sigmoid\"):\n",
        "        newLayer[i] = (1 / (1 + pow(math.e, -1 * newLayer[i])))\n",
        "\n",
        "      elif (activation == \"relu\"):\n",
        "        newLayer[i] = (max(0.1*newLayer[i], newLayer[i]))\n",
        "\n",
        "      else:\n",
        "        print(\"ERROR: Invalid Choice.\")\n",
        "        return 0\n",
        "\n",
        "    return newLayer\n",
        "\n",
        "  def outputLayer(self, lastHidden):\n",
        "    outLayer = []\n",
        "    for i in range(self.outputClass):\n",
        "      outLayer.append(node(lastHidden, [cp.random.random() for j in range(len(self.inputVector))], activation='sigmoid'))\n",
        "\n",
        "    endVals = []\n",
        "    for i in range(self.outputClass):\n",
        "      endVals.append(outLayer[i].nodeVal)\n",
        "      #print(\"Class \", i, \" : \", outLayer[i].nodeVal)\n",
        "\n",
        "    return endVals.index(max(endVals))\n",
        "\n",
        "  def printResult(self):\n",
        "    print(\"Predicted Class: \", self. outputIndex)\n",
        "\n",
        "  def getPrediction(self):\n",
        "    return self.outputIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing CuPy Model"
      ],
      "metadata": {
        "id": "4LhtMsnMOTkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = MLPcupy()\n",
        "outputCuPy = cp.zeros(len(df_X))"
      ],
      "metadata": {
        "id": "iadSlgpiOUKo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testGPUModel(model, inVector, outClasses, appendList = []):\n",
        "  for i in range(len(inVector)):\n",
        "    model.activate(cp.array(inVector[i]), outClasses)\n",
        "    appendList[i] = model.getPrediction()"
      ],
      "metadata": {
        "id": "nsd0LJSSYdTN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testGPUModel(model2, cp.array(df_X), 3, outputCuPy)"
      ],
      "metadata": {
        "id": "dly1_APuYmGT",
        "outputId": "46b77eff-2cba-4f06-f029-9712f8f5dae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "__call__() takes exactly 3 positional arguments (2 given)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cdf73d63f9e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestGPUModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCuPy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-27a7c19e3df0>\u001b[0m in \u001b[0;36mtestGPUModel\u001b[0;34m(model, inVector, outClasses, appendList)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestGPUModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutClasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minVector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mappendList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f7f597def610>\u001b[0m in \u001b[0;36mactivate\u001b[0;34m(self, inputVector, numClass)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Simulate hidden later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumNodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;31m#print(layer1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumNodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f7f597def610>\u001b[0m in \u001b[0;36maddLayer\u001b[0;34m(self, numNodes, prevLayer, activation)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;31m#nodeSum_kernel(const float *inputVec, const float *inputWeight, float *outputNode, const float bias, const int size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m#newLayer[i] = nodeSum_kernel(cp.array(prevLayer), cp.array(weights), cp.random.random()) + bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mnodeSum_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m       \u001b[0;31m#print(\"Node \", i, \" : \", newLayer[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/raw.pyx\u001b[0m in \u001b[0;36mcupy._core.raw.RawKernel.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __call__() takes exactly 3 positional arguments (2 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trueOutput = np.array(df_y)\n",
        "predictedCuPy = np.array(outputCuPy.get())\n",
        "\n",
        "correctPreds, totalPreds = 0, len(trueOutput)\n",
        "for i in range(totalPreds):\n",
        "  if predictedCuPy[i] == trueOutput[i]:\n",
        "    correctPreds = correctPreds + 1\n",
        "\n",
        "print(\"Correct Predictions / Total Predictions: {} / {} .\".format(correctPreds, totalPreds))\n",
        "print(\"Custom Feedforward Neural Network is: {} % Accurate\".format(round(correctPreds/totalPreds * 100), 2))"
      ],
      "metadata": {
        "id": "J_TGNDRgYQtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOdB-cq3faJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}