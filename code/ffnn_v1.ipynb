{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXgX0NF8OMjJ",
        "outputId": "a6cb4f41-0b82-4bd1-830a-0caed03ae1ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.2.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vbncErZOMjK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Implementation of a Node\n",
        "# A node should be able to take an input vector (which is either the input or the previous layer)\n",
        "# Sum the values from the previous node\n",
        "# Pass the sum to an activation value\n",
        "# Return the value as its own value\n",
        "\n",
        "class node(object):\n",
        "  def __init__(self, inputVec = [], weight = [], activation = None):\n",
        "    # Number of Inputs\n",
        "    self.inputVector = inputVec\n",
        "    self.nodeWeights = weight\n",
        "    self.actSelect = activation\n",
        "    self.bias = np.random.rand()\n",
        "\n",
        "    # Summation of Connected Notes\n",
        "    self.nodeSum = self.summationNodes()\n",
        "\n",
        "    # Activation function\n",
        "    self.nodeVal = self.activation()\n",
        "\n",
        "  # Parallelizable for all input values\n",
        "  def summationNodes(self):\n",
        "    sumOfVec = 0\n",
        "    for (i, j) in zip(self.inputVector, self.nodeWeights):\n",
        "        sumOfVec = sumOfVec + i * j\n",
        "    return (sumOfVec + self.bias)\n",
        "\n",
        "  def activation(self):\n",
        "    if (self.actSelect == \"sigmoid\"):\n",
        "      return (1 / (1 + pow(math.e, -self.nodeSum)))\n",
        "\n",
        "    if (self.actSelect == \"relu\"):\n",
        "      return (max(0.1*self.nodeSum, self.nodeSum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix53YnD_OMjL"
      },
      "outputs": [],
      "source": [
        "# For the mutli-layer perceptron\n",
        "# We should first be able to store the input vector in an array\n",
        "# Create N (user-defined number) nodes\n",
        "# Allow users to add layers with custom nodes as a method of the class\n",
        "# The output node automatically implements\n",
        "\n",
        "class mlp(node):\n",
        "\n",
        "  def __init__ (self):\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = None\n",
        "    self.outputClass = []\n",
        "    self.inputVector = [] # This is the vector we pass to the first hidden layer\n",
        "    self.outputVal = None\n",
        "    self.outputIndex = None\n",
        "\n",
        "  def activate(self, inputVector, numClass):\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = len(inputVector)\n",
        "    self.outputClass = numClass\n",
        "    self.inputVector = inputVector # This is the vector we pass to the first hidden layer\n",
        "\n",
        "    # Simulate hidden later\n",
        "    layer1 = self.addLayer(numNodes = 10, prevLayer = self.inputVector)\n",
        "    layer2 = self.addLayer(numNodes = 10, prevLayer = layer1)\n",
        "    layer3 = self.addLayer(numNodes = 10, prevLayer = layer2)\n",
        "    layer4 = self.addLayer(numNodes = 5, prevLayer = layer3)\n",
        "    self.outputVal, self.outputIndex = self.outputLayer(layer4)\n",
        "\n",
        "  # This intendeds to simulate the hidden layers\n",
        "  def addLayer(self, numNodes = None, prevLayer = None):\n",
        "    #weights = [np.random.rand() for i in range(len(inputVector))]\n",
        "\n",
        "    if numNodes == None:\n",
        "      numNodes = self.inputSize\n",
        "\n",
        "    nextLayer = []\n",
        "    for i in range(numNodes):\n",
        "      # Create the nodes\n",
        "      nextLayer.append(node(self.inputVector, [np.random.rand() for j in range(len(self.inputVector))], activation='relu'))\n",
        "\n",
        "    outputValues = []\n",
        "    for i in nextLayer:\n",
        "      i.summationNodes()\n",
        "      i.activation()\n",
        "      outputValues.append(i.nodeVal)\n",
        "\n",
        "    return outputValues\n",
        "\n",
        "  def outputLayer(self, lastHidden):\n",
        "    outLayer = []\n",
        "    for i in range(self.outputClass):\n",
        "      outLayer.append(node(lastHidden, [np.random.rand() for j in range(len(self.inputVector))], activation='sigmoid'))\n",
        "\n",
        "    endVals = []\n",
        "    for i in range(self.outputClass):\n",
        "      endVals.append(outLayer[i].nodeVal)\n",
        "      #print(\"Class \", i, \" : \", outLayer[i].nodeVal)\n",
        "\n",
        "    return max(endVals), endVals.index(max(endVals))\n",
        "\n",
        "  def printResult(self):\n",
        "    print(\"Predicted Class: \", self. outputIndex)\n",
        "\n",
        "  def getPrediction(self):\n",
        "    return self.outputIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMwSVNr6OMjL"
      },
      "source": [
        "# Sample with the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDeWLDQ6OMjM",
        "outputId": "9f50934d-8b2a-47c8-f0ed-d3221ed9a725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.0.6)\n"
          ]
        }
      ],
      "source": [
        "# Loading the IRIS Dataset for Classification\n",
        "!pip install ucimlrepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "df_X = iris.data.features\n",
        "df_y = iris.data.targets\n",
        "\n",
        "df_X = pd.DataFrame(df_X)\n",
        "#df_X.head()\n",
        "\n",
        "df_y = pd.DataFrame(df_y)\n",
        "#df_y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QyUbwVTOMjM",
        "outputId": "e469f365-ba57-49fe-b964-000196c48f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal length  150 non-null    float64\n",
            " 1   sepal width   150 non-null    float64\n",
            " 2   petal length  150 non-null    float64\n",
            " 3   petal width   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   150 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.3+ KB\n",
            "     class\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "..     ...\n",
            "145      2\n",
            "146      2\n",
            "147      2\n",
            "148      2\n",
            "149      2\n",
            "\n",
            "[150 rows x 1 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2433/4190924181.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_y.replace(outMap, inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "class\n",
              "0        50\n",
              "1        50\n",
              "2        50\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform some data wrangling/preparation\n",
        "\n",
        "# Check info on the attributes\n",
        "df_X.info() # All values are same type, check if any missing values\n",
        "df_X.isnull().sum() # To check if there are any null values\n",
        "\n",
        "# Checking the output\n",
        "df_y.info()\n",
        "\n",
        "# Object Types must be converted\n",
        "df_y_original = df_y.copy() # Store the df somewhere before modifying\n",
        "\n",
        "df_y.value_counts()\n",
        "\n",
        "# Reveals Three Classes\n",
        "# Map classes to corresponding numerical values\n",
        "\n",
        "outMap = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
        "df_y.replace(outMap, inplace=True)\n",
        "\n",
        "print(df_y)\n",
        "df_y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpNbdxWTOMjM"
      },
      "source": [
        "# Test out the CPU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEO3XYLlOMjN"
      },
      "outputs": [],
      "source": [
        "def testModel(model, inVector, appendList = []):\n",
        "  for i in inVector:\n",
        "    model.activate(i, 3)\n",
        "    appendList.append(model.getPrediction())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU2euBKHOMjN"
      },
      "outputs": [],
      "source": [
        "predictedVals = []\n",
        "model = mlp()\n",
        "\n",
        "testModel(model, np.array(df_X), predictedVals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzmrjTQ4OMjN",
        "outputId": "d07e7528-ae52-491f-81c9-0834e086c8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct Predictions / Total Predictions: 51 / 150 .\n",
            "Custom Feedforward Neural Network is: 34 % Accurate\n"
          ]
        }
      ],
      "source": [
        "trueOutput = np.array(df_y)\n",
        "\n",
        "correctPreds, totalPreds = 0, len(trueOutput)\n",
        "for i in range(totalPreds):\n",
        "  if predictedVals[i] == trueOutput[i]:\n",
        "    correctPreds = correctPreds + 1\n",
        "\n",
        "print(\"Correct Predictions / Total Predictions: {} / {} .\".format(correctPreds, totalPreds))\n",
        "print(\"Custom Feedforward Neural Network is: {} % Accurate\".format(round(correctPreds/totalPreds * 100), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzonciwQOMjN"
      },
      "source": [
        "# Implementation using CuPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1LansRWOMjN"
      },
      "outputs": [],
      "source": [
        "# For implementation with CuPY\n",
        "import cupy as cp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD-k6mclOMjO"
      },
      "outputs": [],
      "source": [
        "nodeSum_kernel = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void nodeSum_kernel(const float* inputVector, const float* layerWeights, float* outputNode) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    int temp = 0;\n",
        "    for (int i = 0; i < blockDim.x; i++){\n",
        "      temp = temp + inputVector[i] * layerWeights[i];\n",
        "    }\n",
        "\n",
        "    outputNode = temp;\n",
        "}\n",
        "''', 'nodeSum_kernel')\n",
        "\n",
        "class MLPcupy():\n",
        "\n",
        "  def __init__ (self):\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = None\n",
        "    self.outputClass = []\n",
        "    self.inputVector = [] # This is the vector we pass to the first hidden layer\n",
        "    self.outputVal = None\n",
        "    self.outputIndex = None\n",
        "\n",
        "  def activate(self, inputVector, numClass):\n",
        "\n",
        "    # We simulate the input layer here by storing each value\n",
        "    # in the input as an element of a vector\n",
        "    self.inputSize = len(inputVector)\n",
        "    self.outputClass = numClass\n",
        "    self.inputVector = inputVector # This is the vector we pass to the first hidden layer\n",
        "\n",
        "    # Simulate hidden later\n",
        "    layer1 = self.addLayer(numNodes = 10, prevLayer = self.inputVector)\n",
        "    print(layer1)\n",
        "    layer2 = self.addLayer(numNodes = 10, prevLayer = layer1)\n",
        "    print(layer2)\n",
        "    layer3 = self.addLayer(numNodes = 10, prevLayer = layer2)\n",
        "    print(layer3)\n",
        "    layer4 = self.addLayer(numNodes = 5, prevLayer = layer3)\n",
        "    print(layer4)\n",
        "    self.outputIndex = self.outputLayer(layer4)\n",
        "\n",
        "\n",
        "\n",
        "  # This intendeds to simulate the hidden layers\n",
        "  def addLayer(self, numNodes = None, prevLayer = None):\n",
        "\n",
        "    if numNodes == None:\n",
        "      print(\"Indicate number of Nodes.\")\n",
        "      return\n",
        "\n",
        "    # This will be where we store the new values\n",
        "    newLayer = cp.zeros(numNodes)\n",
        "\n",
        "    # Generate the weights\n",
        "    # weights = [cp.random.rand() for i in range(len(prevLayer))]\n",
        "    weights = []\n",
        "    for i in range(numNodes):\n",
        "      weights.append([cp.random.rand() for i in range(len(prevLayer))])\n",
        "\n",
        "    threads_per_block = 512\n",
        "    size = numNodes\n",
        "    grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "    block_size = (threads_per_block, 1, 1)\n",
        "\n",
        "    for i in newLayer:\n",
        "    # add_kernel(grid_size, block_size, (x1, x2, y, size))\n",
        "    # nodeSum_kernel(const float* inputVector, const float* layerWeights, float* outputNode, const float* bias)\n",
        "      nodeSum_kernel(grid_size, block_size, (cp.array(prevLayer), (cp.array([cp.random.rand() for i in range(len(prevLayer))])), i))\n",
        "\n",
        "    cp.sum()\n",
        "\n",
        "    return newLayer\n",
        "\n",
        "  def outputLayer(self, lastHidden):\n",
        "    outLayer = []\n",
        "    for i in range(self.outputClass):\n",
        "      outLayer.append(node(lastHidden, [cp.random.rand() for j in range(len(self.inputVector))], activation='sigmoid'))\n",
        "\n",
        "    endVals = []\n",
        "    for i in range(self.outputClass):\n",
        "      endVals.append(outLayer[i].nodeVal)\n",
        "      #print(\"Class \", i, \" : \", outLayer[i].nodeVal)\n",
        "\n",
        "    return endVals.index(max(endVals))\n",
        "\n",
        "  def printResult(self):\n",
        "    print(\"Predicted Class: \", self. outputIndex)\n",
        "\n",
        "  def getPrediction(self):\n",
        "    return self.outputIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "4LhtMsnMOTkT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iadSlgpiOUKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}